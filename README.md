# Portfolio_Repo — Documented Data Intake & Validation Framework (R)

## Overview

This project demonstrates a **documentation-first, reproducible data intake framework** built in R.  
It showcases how heterogeneous data sources can be ingested, documented, validated, and standardized for downstream analytics, reporting, or BI tools.

The emphasis is **data governance, documentation quality, and reproducibility**, rather than exploratory analysis.

---

## Objectives

- Standardize ingestion of mixed-format datasets (CSV, Excel)
- Produce **human-readable documentation** (data catalog)
- Enforce **machine-readable data contracts** (schema YAML)
- Surface schema and quality issues early via validation outputs
- Generate artifacts suitable for analytics pipelines and CI/CD workflows

---

## Repository Structure

```text
.
├── Sample_Sets/                 # Raw sample datasets (CSV, XLSX)
├── R/                           # Reusable, side-effect-free functions
│   ├── utilities.R
│   ├── 01_ingest.R
│   ├── 02_validate.R
│   └── 03_document.R
├── scripts/                     # Executable entry points (CLI / CI)
│   ├── setup.R                  # Install/restore dependencies (renv)
│   ├── run.R                    # Generate documentation + validation artifacts
│   └── test.R                   # Smoke test
├── notebooks/                   # Interactive runbook ("GUI" execution)
│   └── runbook.qmd
├── contracts/                   # Dataset schema definitions (*.schema.yml)
├── docs/
│   ├── DATA_CATALOG.md          # Auto-generated data catalog (committed)
│   ├── SETUP.md                 # Environment notes (Codespaces/Linux)
│   └── decisions/               # Architecture/design decision records (ADRs)
├── output/
│   └── validation/
│       └── validation_summary.csv  # Auto-generated validation output (committed)
├── renv.lock                    # Reproducible dependency lockfile
└── README.md


Included Sample Datasets

The Sample_Sets/ directory contains heterogeneous datasets used to demonstrate intake and documentation patterns, including:

Vehicle sales data

CO₂ emissions data

Energy consumption data

GDP totals

Population totals

Date reference tables

These datasets are treated as raw inputs and are not modified in place.

Examples of Work (Generated Artifacts)

This repository produces and commits key artifacts to demonstrate outputs clearly:

Data Catalog: docs/DATA_CATALOG.md
Summarizes datasets, shapes, and columns to support transparency and downstream use.

Validation Summary: output/validation/validation_summary.csv
Provides a dataset-by-dataset view of whether a schema exists and whether validation passed.

These artifacts are generated by the pipeline and can be reproduced locally.

Documentation Approach

Documentation is separated into multiple layers:

1) Data Catalog (Human-Readable)

Generated at:

docs/DATA_CATALOG.md

2) Data Contracts (Machine-Enforced)

Schemas are stored in:

contracts/*.schema.yml

Validation is performed during pipeline execution and summarized at:

output/validation/validation_summary.csv

3) Design Decisions

Architecture and trade-offs are recorded as lightweight ADRs:

docs/decisions/

This mirrors practices used in production and regulated environments.

How to Run Locally
1) Restore dependencies

From the repo root:

Rscript scripts/setup.R

2) Generate documentation + validation outputs
Rscript scripts/run.R


Outputs:

docs/DATA_CATALOG.md

output/validation/validation_summary.csv

3) Run a smoke test
Rscript scripts/test.R

Run Interactively (Runbook)

An interactive runbook is provided for “GUI-style” execution:

notebooks/runbook.qmd

This runbook executes the same underlying pipeline functions and is intended for exploratory execution and demonstration.

Notes

If you are running in Codespaces or a locked-down environment, see docs/SETUP.md.

The repo is structured to be CI/CD-friendly: scripts/run.R is the non-interactive entry point.